{
	"// Note": "This is an example configuration for multiple model providers",
	"// Ollama (local)": "Default provider running locally",
	"fast_model_ollama": {
		"provider": "ollama",
		"url": "http://localhost:11434",
		"model": "qwen3:0.6b",
		"temperature": 0.7,
		"top_p": 0.95
	},
	"// OpenAI": "Set OPENAI_API_KEY environment variable",
	"fast_model_openai": {
		"provider": "openai",
		"url": "https://api.openai.com/v1",
		"model": "gpt-4o-mini",
		"api_key": "OPENAI_API_KEY",
		"temperature": 0.7,
		"top_p": 0.95,
		"max_tokens": 4096
	},
	"// Anthropic": "Set ANTHROPIC_API_KEY environment variable",
	"heavy_model_anthropic": {
		"provider": "anthropic",
		"url": "https://api.anthropic.com/v1",
		"model": "claude-3-5-sonnet-20241022",
		"api_key": "ANTHROPIC_API_KEY",
		"temperature": 0.7,
		"top_p": 0.95,
		"max_tokens": 8192
	},
	"// Groq": "Set GROQ_API_KEY environment variable",
	"heavy_model_groq": {
		"provider": "groq",
		"url": "https://api.groq.com/openai/v1",
		"model": "llama-3.3-70b-versatile",
		"api_key": "GROQ_API_KEY",
		"temperature": 0.7,
		"top_p": 0.95,
		"max_tokens": 8192
	},
	"// Environment variables you can set:": "",
	"// NEURO_ENV": "production | development | test",
	"// NEURO_OLLAMA_URL": "Override Ollama URL",
	"// NEURO_FAST_MODEL": "Override fast model name",
	"// NEURO_HEAVY_MODEL": "Override heavy model name",
	"// OPENAI_API_KEY": "Your OpenAI API key",
	"// ANTHROPIC_API_KEY": "Your Anthropic API key",
	"// GROQ_API_KEY": "Your Groq API key"
}